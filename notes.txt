if nvidia gpus are used with cuda api, then we can convert fp32 to tf32 which is just a 
truncated version of 32 bits with the mantissa cut to 10 bits instead of 23, and the sign
and bias exponent bits remain the same, where tf32 stands for tensorfloat-32, and the result
of this is an 8time improvement over fp32 TOPS

tf32 could be further reduced to bf16 where there are 7 mantissa bits 

fp16 could also be used but it truncates the bias exponent bits too, from 8 to 5 and hence
the range of nos decreases, hence differnet approaches like gradient scaling needs to be
used, which does become an annoyance, hence bf16 is preferred

now looking at torch.compile which can speed up the training code by a HUGE extent. Its
basically like a compiler, like gcc for C/C++ code. It looks at the entire code as a single
object and does not use the python interpreter, once the compiler object is formed, since
it knows what is where, it does not go through the code in eager mode as a python interpreter
would do. 

some notes related to server side domain

in the C server implemenation here its designed to be multithreaded, hence when we put in
localhost:8080/main.html say, a thread gets created which handles this req, so when the
server sends main.html to the browser(client) as a res, then the browser being a special
client, parses the html file and sees the requirement of main.css and main.jpg, and 
send separate GET reqs to the server in different thread to the server, hence we end up seeing
multiple GET reqs by the client even though we only entered localhost:8080/main.html

also the input field needs to be within the form so that the contents get sent as a req
to the server, also if we put "/submit" as value for action attr, then the req gets 
sent to the endpoint /submit, more specifically, it gets sent to localhost:8080/submit, but
that is given its a POST method, if its GET it gets appended to the url itself, where we say
get localhost:8080/submit?username=something, and then it can be parsed that way

(note: never ever use git lfs, its a pain and annoying, asks for ssh to be entered 5 times
everytime, and still does not push large files to the repo, very bad, instead what I did
was put the saved_models folder to .gitignore so that they are not tracked, its better
and also does not actually expose the params of the model)

another issue I ran into was when I submitted my form data, it did show up as GET req on 
my server logs, but a new tab opened up every time which represented the form tab and this was\
very annoying, so i decided the prevent the defualt behaviour of the "submit" event which was
attatched to the from DOM element, but this prevented the sending of the GET req too, but ended
up adjusting the server code to serve the same file itself which was present in the Referer
header in the GET req sent by the client when the req has "submit?prompt=" in it, hence instead
of serving the client the form file, it serves it the same file in where it was


. might not work as expected in regex in POSIX, as its a lazy quantifier

also note to self, to put a folder in .gitignore which was already being tracked by git
we have to first remove it from being tracked and then put it in .gitignore, that can be done
by
    git rm -r --cached folder

then add that folder to .gitignore


another lesson learnt is that within a loop, when something is printed to and no '\n' is 
encountered, then, all the print values get stored within the buffer, and that buffer is flushed
to stdout only when the loop is completed, so to prevent that flush=True is set within print
hence the buffer is flushed everytime. In case of a normal prog like for i in range(2): print(i)
the '\n' is encountered every time, hence for every iter of the loop, the buffer is flushed, but
in my case I set end="" not "\n" hence all the values keep getting stored in the buffer. Same
thing occurs for writing to a file, where file.flush() needs to be done

also used system() method in C to run the python script with the prompt as the second
argv CLA, where system() is a method in C which executed shell commands, it does it by 
spawning new child shell process and running the command specified. However since there is a
dynamic element involved which is that prompt itself comes in during runtime, using sprintf() 
becomes better, which behaves the same way. Also, system() internally calls fork() to
create a new process and then execvp() to execute the given command. Here, I used 
snprintf() and then system() as it prevents buffer overflow, and one more thing to keep in mind is that the buffer
which is passed as an arg to snprintf() holds the final substituted string command that is to
be executed, and then system() is used to execute the command which is stored in a buffer


finally, the crown jewel of this project, the dynamic update of the text shown in the client
side. I initially tried to do it using just the server backend that I made, using diff endpoints
trying to send event-stream type data for the chars to the client, but it honestly got too bloated
so i just went plain js, since the text was being stored in real time in the response text file
anyways, i just fetched the contents from the file once every 100ms using fetch() and updated
the div element where the text was to be shown. I also decided to make the div element a rectangle
where the chars would not overflow over the div, but instead flow down in the div itself

Another thing I impemented was that i stopped the polling(fetch) after a certain period of time
of unchanged contents in the response.txt file, this is to prevent repeated fetching even 
when not needed, and again all this was done in js itself, also stopping the fetching entierly
when no updates happen for a while actually also stops the fetching for future changes too, hence
causing a bug where the dynamic update of the content does not happen, for this we can slow
down the fetch rate by a lot when no changes occur

Another thing about css is the transform property, say whats given is
    transform: translate(-50%) 
for a <p> ele, now if left:50% is also mentioned, then its left side will be at the centre but
the entirety of the p ele will bulge out to the right, hence we need to also shift the p ele
to the left by 50% of its width to essentially centre it, and this is what this means. The same
can be done for both hori and ver centring using transform: translate(-50%, -50%)


now the aim is to deploy it, and for this I use render.com, here i can connect the repo
where this project is present and it can be deployed, altough it does sleep when its inactive
and is not meant to be production grade. For this I used getenv("PORT") so that it sets the
env port to something dynamic when it runs the server executable, also render will 
automatically route traffic from the url https://name.com (assume) to the assigned port
so that users dont need to type the actual port every single time